@@ -0,0 +1,275 @@
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://www.kaggle.com/c/bike-sharing-demand\\ndatetime - hourly date + timestamp  \\nseason -  1 = spring, 2 = summer, 3 = fall, 4 = winter \\nholiday - whether the day is considered a holiday\\nworkingday - whether the day is neither a weekend nor holiday\\nweather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \\n4: Heavy Rain +...(line truncated)...
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "baseDir = os.path.join('Data')\n",
    "inputPath = os.path.join('Aula04', 'BikeSharing.csv')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "numPartitions = 2\n",
    "csvData = sc.textFile(fileName, numPartitions)\n",
    "header = csvData.take(1)[0]\n",
    "rawData = csvData.filter(lambda x: x!=header)\n",
    "\n",
    "'''\n",
    "https://www.kaggle.com/c/bike-sharing-demand\n",
    "datetime - hourly date + timestamp  \n",
    "season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "holiday - whether the day is considered a holiday\n",
    "workingday - whether the day is neither a weekend nor holiday\n",
    "weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "temp - temperature in Celsius\n",
    "atemp - \"feels like\" temperature in Celsius\n",
    "humidity - relative humidity\n",
    "windspeed - wind speed\n",
    "casual - number of non-registered user rentals initiated\n",
    "registered - number of registered user rentals initiated\n",
    "count - number of total rentals\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def discrete(value, max, n):\n",
    "    \"\"\"Divide o intervalo de 0 até 'max' em 'n' intervalos de mesmo tamanho e retorna qual intervalo 'value' corresponde.\n",
    "    \n",
    "    Args:\n",
    "        value: valor a ser discretizado.\n",
    "        max: valor maximo que 'value' pode assumir.\n",
    "        n: número de classes que serão levadas\n",
    "    \"\"\"\n",
    "    \n",
    "    if value==max: value-=1\n",
    "    gap=max/n\n",
    "    return int(math.floor(value/gap))\n",
    "\n",
    "    \n",
    "\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    data = point.split(',')\n",
    "    Date = dt.strptime(data[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    DateList = [Date.year-2011, Date.month, Date.hour]   \n",
    "    season = data[1]\n",
    "    workingday=data[3]\n",
    "    weather =data[4]\n",
    "    sense=discrete(float(data[6]),46.,8)\n",
    "    hum=discrete(float(data[7]),100.,8)\n",
    "    wind=discrete(float(data[8]),57.,8)\n",
    "    #features = DenseVector(DateList + season + realValues)\n",
    "    features = DenseVector(DateList + [season]+ [workingday] + [sense] + [hum] + [wind] + [weather])# + realValues)\n",
    "    \n",
    "    label = discrete(int(data[-1]),997,10)\n",
    "    \n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "\n",
    "rawTrainData, rawValData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "\n",
    "parsedTrainData = rawTrainData.map(parsePoint).cache()\n",
    "parsedValData = rawValData.map(parsePoint).cache()\n",
    "parsedTestData = rawTestData.map(parsePoint).cache()\n",
    "\n",
    "print parsedTrainData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.426679280984\n"
     ]
    }
   ],
   "source": [
    "#Função própria do Spark\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "\n",
    "# Train a naive Bayes model.\n",
    "model = NaiveBayes.train(parsedTrainData, 1.0)\n",
    "\n",
    "# Make prediction and test accuracy.\n",
    "predictionAndLabel = parsedTestData.map(lambda p : (model.predict(p.features), p.label))\n",
    "accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / parsedTestData.count()\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((6.0, 4.0), 0.004565688848304988),\n",
       " ((2.0, 4.0), 0.04246090628923639),\n",
       " ((1.0, 3.0), 0.05170642620705399),\n",
       " ((3.0, 1.0), 0.0097020888026481),\n",
       " ((3.0, 3.0), 0.030704257504851045),\n",
       " ((7.0, 3.0), 0.003766693299851615),\n",
       " ((8.0, 4.0), 0.0017121333181143706),\n",
       " ((7.0, 1.0), 0.0007989955484533729),\n",
       " ((4.0, 4.0), 0.016664764296313205),\n",
       " ((4.0, 2.0), 0.015523342084236958),\n",
       " ((0.0, 2.0), 0.08709051478141765),\n",
       " ((6.0, 2.0), 0.007875813263326105),\n",
       " ((9.0, 3.0), 0.0009131377696609977),\n",
       " ((2.0, 2.0), 0.04325990183768976),\n",
       " ((5.0, 1.0), 0.0035384088574363657),\n",
       " ((0.0, 4.0), 0.08560666590571853),\n",
       " ((8.0, 2.0), 0.0020545599817372445),\n",
       " ((1.0, 1.0), 0.05444583951603698),\n",
       " ((5.0, 3.0), 0.011300079899554845),\n",
       " ((1.0, 2.0), 0.05056500399497774),\n",
       " ((0.0, 1.0), 0.14438990982764524),\n",
       " ((5.0, 4.0), 0.009587946581440476),\n",
       " ((4.0, 1.0), 0.004793973290720238),\n",
       " ((9.0, 4.0), 0.0005707111060381235),\n",
       " ((7.0, 4.0), 0.002396986645360119),\n",
       " ((8.0, 1.0), 0.0001141422212076247),\n",
       " ((3.0, 4.0), 0.02762241753224518),\n",
       " ((6.0, 1.0), 0.0012555644332838717),\n",
       " ((3.0, 2.0), 0.029448693071567174),\n",
       " ((2.0, 1.0), 0.027508275311037552),\n",
       " ((6.0, 3.0), 0.0063919643876269834),\n",
       " ((2.0, 3.0), 0.04337404405889739),\n",
       " ((1.0, 4.0), 0.06118023056728684),\n",
       " ((4.0, 3.0), 0.021458737587033445),\n",
       " ((8.0, 3.0), 0.0036525510786439906),\n",
       " ((0.0, 3.0), 0.07556215043944756),\n",
       " ((5.0, 2.0), 0.012555644332838718),\n",
       " ((7.0, 2.0), 0.0038808355210592396)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fiz os dados do desafio 1 funcionarem com o Bayes, só falta começar agora.\n",
    "import math\n",
    "#Para cada classe c, calcular P(c). Para cada valor de atributo a, calcular P(a|c)\n",
    "RDDlen=parsedTrainData.count()\n",
    "#Probabilidade de cada classe\n",
    "PClassesRDD=(parsedTrainData\n",
    "                .map(lambda lp:(lp.label,1))\n",
    "                .reduceByKey(lambda x,y:x+y)\n",
    "                .map(lambda (x,y):(x,math.log(10,y/float(RDDlen)))))\n",
    "PClassesRDD.collect()\n",
    "\n",
    "#Probabilidade de cada atributo\n",
    "#Tiramos a quantidade de atributos de uma amostra\n",
    "amostra = parsedTrainData.take(1)[0]\n",
    "\n",
    "#quantidade de atributos\n",
    "nAttri=len(amostra.features)\n",
    "#lista de RDDs para cada atributo\n",
    "AttributesRDDs=[]\n",
    "#lista de RDDs para cada par atributo/classe\n",
    "AttributeClassesRDDs=[]\n",
    "#laço para percorrer os atributos\n",
    "for i in range(nAttri):\n",
    "    AttriRDD==(parsedTrainData\n",
    "                .map(lambda lp:(lp.features[i],1))\n",
    "                .reduceByKey(lambda x,y:x+y)\n",
    "                .map(lambda (x,y):(x,math.log(10,y/float(RDDlen)))))\n",
    "    AttributesRDDs.append(AttriRDD)\n",
    "    AttriClassRDD=(parsedTrainData\n",
    "                    .map(lambda lp:((lp.label,lp.features[i]),1))\n",
    "                    .reduceByKey(lambda x,y:x+y)\n",
    "                    .map(lambda (x,y):(x, math.log(10,y/float(RDDlen)))))\n",
    "    AttributeClassesRDDs.append(AttriClassRDD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
