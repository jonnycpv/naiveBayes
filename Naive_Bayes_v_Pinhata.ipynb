{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16']\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "baseDir = os.path.join('Data')\n",
    "inputPath = os.path.join('Aula04', 'dac_sample.txt')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "if os.path.isfile(fileName):\n",
    "    rawData = (sc\n",
    "               .textFile(fileName, 4)\n",
    "               .map(lambda x: x.replace('\\t', ',')))  # work with either ',' or '\\t' separated data\n",
    "    print rawData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80139 9949 9912 100000\n",
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16', u'0,2,0,44,1,102,8,2,2,4,1,1,,4,68fd1e64,f0cf0024,6f67f7e5,41274cd7,25c83c98,fe6b92e5,922afcc0,0b153874,a73ee510,2b53e5fb,4f1b46f3,623049e6,d7020589,b28479f6,e6c5b5cd,c92f3b61,07c540c4,b04e4670,21ddcdc9,5840adea,60f6221e,,3a171ecb,43f13e8b,e8b83407,731c3655', u'0,2,0,1,14,767,89,4,2,245,1,3,3,45,287e684f,0a519c5c,02cf9876,c18be181,25c83c98,7e0ccccf,c78204a1,0b153874,a73ee510,3b08e48b,5f5e6091,8fe001f4,aa655a2f,07d13a8f,6dc710ed,36103458,8efede7f,3412118d,,,e587c466,ad3062eb,3a171ecb,3b183c5c,,', u'0,,893,,,4392,,0,0,0,,0,,,68fd1e64,2c16a946,a9a87e68,2e17d6f6,25c83c98,fe6b92e5,2e8a689b,0b153874,a73ee510,efea433b,e51ddf94,a30567ca,3516f6e6,07d13a8f,18231224,52b8680f,1e88c74f,74ef3502,,,6b3a5ca6,,3a171ecb,9117a34a,,', u'0,3,-1,,0,2,0,3,0,0,1,1,,0,8cf07265,ae46a29d,c81688bb,f922efad,25c83c98,13718bbd,ad9fa255,0b153874,a73ee510,5282c137,e5d8af57,66a76a26,f06c53ac,1adce6ef,8ff4b403,01adbab4,1e88c74f,26b3c7a7,,,21c9516a,,32c7478e,b34f3128,,']\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "# Cache the data\n",
    "rawTrainData.cache()\n",
    "rawValidationData.cache()\n",
    "rawTestData.cache()\n",
    "\n",
    "nTrain = rawTrainData.count()\n",
    "nVal = rawValidationData.count()\n",
    "nTest = rawTestData.count()\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print rawData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EXERCICIO\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    return point.split(\",\")\n",
    "    \n",
    "\n",
    "#preparando as bases, separando os valores utilizando o separador \",\"\n",
    "parsedTrainFeat = rawTrainData.map(parsePoint)\n",
    "parsedValidationFeat = rawValidationData.map(parsePoint)\n",
    "parsedTestFeat = rawTestData.map(parsePoint)\n",
    "\n",
    "\n",
    "#funcao para enumerar as bases\n",
    "def makeReady(Base):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Base: Uma lista no seguinte formato\n",
    "                [(label, feature1, feature3,..., featuren), (label2, feature1, feature2,..., featuren), etc]\n",
    "        \n",
    "        Returns: Retorna uma base enumerada da seguinte forma\n",
    "                [(label1, (1, feature1), (2, feature2), ..., (n, featuren)), \n",
    "                ((label2, (1, feature1), (2, feature2), ..., (n, featuren)), etc]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    return (Base\n",
    "                .map(lambda x: list(enumerate(x)))\n",
    "                .map(lambda x: (int(x[0][1]), x[1:])))\n",
    "   \n",
    "\n",
    "    \n",
    "#bases prontas para serem usadas\n",
    "readyTrainRDD = makeReady(parsedTrainFeat)\n",
    "readyValidationRDD = makeReady(parsedValidationFeat)\n",
    "readyTestRDD = makeReady(parsedTestFeat)\n",
    "\n",
    "\n",
    "#criar o dicionário de palavras. \n",
    "#junta todas as features e reduz para que contenha apenas uma de cada\n",
    "#tipo\n",
    "categoriasRDD = (readyTrainRDD\n",
    "                 .map(lambda (x,y): y)\n",
    "                .flatMap(lambda x: x)\n",
    "                .map(lambda (x,y): ((x,y),1))\n",
    "                .reduceByKey(lambda x,y: x)\n",
    "                .map(lambda ((x,y),z): (x,y))\n",
    "                )\n",
    "\n",
    "#coloca índice em cada feature para que cada uma possa ter um valor \n",
    "#único\n",
    "orderedCategorias = sc.parallelize(sorted(categoriasRDD.collect()))\n",
    "orderedZipCategorias = orderedCategorias.zipWithIndex()\n",
    "\n",
    "\n",
    "#cria dicionario e calcula número de categorias\n",
    "dictCategorias = dict(orderedZipCategorias.collect())\n",
    "numCategorias = len(dictCategorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "\n",
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    #return SparseVector(numOHEFeats, [OHEDict.get(rawFeats[i],0.0) for i in range(len(rawFeats))], [1 for i in range(len(rawFeats))])\n",
    "    return SparseVector(numOHEFeats, [OHEDict[rawFeats[i]] for i in range(len(rawFeats))], [1 for i in range(len(rawFeats))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#funçao para transformar RDD em um vetor que pode ser usado para calcular as probabilidades\n",
    "def makeVector(readyBase):\n",
    "    \"\"\"\n",
    "        Args: \n",
    "            readyBase: base no formato \n",
    "                [(label1, (1, feature1), (2, feature2), ..., (n, featuren)), \n",
    "                ((label2, (1, feature1), (2, feature2), ..., (n, featuren)), etc]\n",
    "        Returns:\n",
    "            retorna uma RDD de tuplas, cujo primeiro valor é uma label e o segundo é um \n",
    "            SparseVector informando as posições das features encontradas\n",
    "    \"\"\"\n",
    "    return readyBase.map(lambda x: (x[0], oneHotEncoding(x[1], dictCategorias, numCategorias)))\n",
    "\n",
    "\n",
    "#transforma as bases prontas para poderem ser utilizadas\n",
    "vectorTrainRDD = makeVector(readyTrainRDD)\n",
    "vectorValidationRDD = makeVector(readyValidationRDD)\n",
    "vectorTestRDD = makeVector(readyTestRDD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Funcoes que calculam as probabilidades considerando a classe escolhida e \n",
    "    os atributos. (Tratados acima como label e features respectivamentes)\n",
    "    \n",
    "    Argumentos em comum:\n",
    "        vectorTrain: RDD no formato (label/classe, SparseVector), onde o SparseVector informa quais \n",
    "                atributos a entrada contém\n",
    "            \n",
    "        classNum: O valor para a classe, que no caso pode ser 1 ou 0. Onde 1 corresponde ao ad clicado\n",
    "                e 0 corresponde ao ad não clicado.\n",
    "                \n",
    "        attrib: Atributos considerados para calcular a possibilidade de ter um clique ou não\n",
    "        \n",
    "        nAttrib: quantidade de atributos sendo considerados no cálculo. Valor inicia com \n",
    "                o valor 1 e é utilizado para evitar uma multiplicação por 0 dado um \n",
    "                atributo que nunca apareceu na base de treinos.\n",
    "\"\"\"\n",
    "\n",
    "#funcao que retorna a probabilidade de um atributo dado uma classe\n",
    "def probAttribClass(vectorTrain, classNum, attrib, nAttrib=1):\n",
    "    classCount = vectorTrain.filter(lambda (x,y): x==classNum).count() \n",
    "    attriClassCount = vectorTrain.filter(lambda (x,y): x==classNum and y[attrib]==1).count()\n",
    "    return (attriClassCount+1)/float(classCount+nAttrib)\n",
    "\n",
    "#funcao que retorna a probabilidade de uma classe\n",
    "def probClass(vectorTrain, classNum, nAttrib=1):\n",
    "    classCount = vectorTrain.filter(lambda (x,y): x==classNum).count()\n",
    "    nTrain = vectorTrain.count()\n",
    "    return (classCount+1)/float(nTrain+nAttrib)\n",
    "\n",
    "#funcao que retorna a probabilidade de um atributo\n",
    "def probAttrib(vectorTrain, attrib, nAttrib=1):\n",
    "    attribCount = vectorTrain.filter(lambda (x,y): y[attrib]==1).count()\n",
    "    nTrain = vectorTrain.count()\n",
    "    return (attribCount+1)/float(nTrain+nAttrib)\n",
    "\n",
    "#funcao que retorna a probabilidade de uma classe dados vários atributos\n",
    "def probClassAttrib(vectorTrain, classNum, attribList):\n",
    "    probList = map(lambda x: (probAttribClass(vectorTrain, classNum, x)*probClass(vectorTrain, classNum))/probAttrib(vectorTrain, x), attribList)\n",
    "    return reduce(lambda x,y: x*y, probList)\n",
    "\n",
    "#funcao teste que mostra as probabilidades sem a multiplicação entre elas\n",
    "def probClassAttribTest(vectorTrain, classNum, attribList):\n",
    "    nAttrib = len(attribList)\n",
    "    return map(lambda x: (probAttribClass(vectorTrain, classNum, x, nAttrib)*probClass(vectorTrain, classNum, nAttrib))/probAttrib(vectorTrain, x, nAttrib), attribList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "#print vectorTrainRDD.take(2)\n",
    "\n",
    "#print probClassAttribTest(vectorValidationRDD, 1, [2, 3, 4])\n",
    "print probClassAttrib(vectorTrainRDD, 0, [2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
